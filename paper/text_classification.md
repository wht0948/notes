# Unsupervised Domain Adaptation by Backpropagation
https://arxiv.org/pdf/1409.7495.pdf

![image](https://user-images.githubusercontent.com/32132519/168024177-28333171-c4fe-4c0d-8e14-ddec62772e1c.png)

背景：在迁移学习中，会存在大量的一个领域的数据和另一个领域的少量数据甚至没有数据，目的是希望训练一个模型，能进行领域间的迁移。需要该模型通用性较强。

方法：模型分为三部分，特征提取(绿色)、标签分类(蓝色)、领域分类(红色)。对于原领域的大量数据，会同时经过三个部分，绿色+蓝色是正常的训练过程，

此外还有一个红色部分，是用来预测这个数据是属于原领域还是新领域，不过绿色和红色中间会有一个GRL(梯度反转层)，GRL的作用不影响前向传播，但是会将反向传播的梯度反过来，这样就会形成一个对抗，红色部分希望能预测出来，但是绿色部分不希望红色部分能预测出来。

最终训练完成后，提取出的特征会使模型预测不出来这是来自那个数据源，说明这个特征是领域无关的，所以可以进行领域间的迁移。


# Feature Projection for Improved Text Classification
https://aclanthology.org/2020.acl-main.726.pdf

![image](https://user-images.githubusercontent.com/32132519/168023287-d01409e9-d236-4810-b0b5-87bd2a3ff6c9.png)

背景：现有的模型会压缩文本中的信息，去掉冗余信息保留关键信息进行分类，但是压缩还有提升的空间

方法：模型包含两个部分，关键信息提取模型P-Net和通用信息提取模型C-Net，C-Net输入文本embedding后得到一个向量，这个向量经过GRL(梯度反转层)后再过一个分类器进行分类，这里作者认为经过梯度反转层之后特征会倾向于提取通用特征(存疑，这里特征全部为0也可以，个人认为C-Net可以使用再增加一个head，去重构输入，这样训练的向量是无法预测出label但是能重构出输入，说明这个向量是通用特征)

在得到通用特征后，作者认为通过右边的部分，通过映射以及向量向减，会提取出关键特征，使用这个关键特征去进行分类，效果会更好。
